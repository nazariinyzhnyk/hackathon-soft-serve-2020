{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "pd.options.display.max_colwidth=100\n",
    "pd.options.display.max_columns=300\n",
    "\n",
    "employees = pd.read_csv(\"../data/employees.csv\")\n",
    "history = pd.read_csv(\"../data/history.csv\")\n",
    "submission = pd.read_csv(\"../data/submission.csv\")\n",
    "\n",
    "# history.loc[:,'Date'] = list(pd.to_datetime(history['Date']))\n",
    "\n",
    "def get_month(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[0])\n",
    "\n",
    "def get_year(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[-1])\n",
    "\n",
    "df = history.merge(employees)\n",
    "\n",
    "# for data labeling\n",
    "def label_df(data, n_month=3):\n",
    "    labels = []\n",
    "    for emp in data.EmployeeID.unique():\n",
    "        curr_emp = list(data[data.EmployeeID == emp]['DismissalDate'])\n",
    "        len_emp = len(curr_emp)\n",
    "        if pd.isnull(curr_emp[0]):\n",
    "            labels += [0 for _ in range(len_emp - n_month)] + [2 for _ in range(n_month)]\n",
    "        else:\n",
    "            labels += [0 for _ in range(len_emp - n_month)] + [1 for _ in range(n_month)]\n",
    "    return labels\n",
    "\n",
    "lbls = label_df(df)\n",
    "df['target'] = lbls\n",
    "df = df[df.target!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1\n",
      "train: 37624\n",
      "val: 4527\n",
      " \n",
      "FOLD #1\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.2724328109953602\n",
      "fold:  2\n",
      "train: 46644\n",
      "val: 4572\n",
      " \n",
      "FOLD #2\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.2361719843188047\n",
      "fold:  3\n",
      "train: 55756\n",
      "val: 4719\n",
      " \n",
      "FOLD #3\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.29528479609929076\n",
      "fold:  4\n",
      "train: 65100\n",
      "val: 4576\n",
      " \n",
      "FOLD #4\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.30095223691328654\n",
      "MEAN OF SCOREs: 0.27621045708168557\n"
     ]
    }
   ],
   "source": [
    "# !pip install imblearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seed(random_state=RANDOM_SEED):\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "def model_fit(X_train, y_train):\n",
    "    clf2 = BalancedRandomForestClassifier(n_estimators=200, n_jobs = 8)\n",
    "    clf2 = clf2.fit(X_train, y_train)\n",
    "    return clf2\n",
    "\n",
    "def model_predict(X, models):\n",
    "    preds = models.predict(X)\n",
    "    return preds\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_drop = ['HiringDate', 'DismissalDate']\n",
    "\n",
    "cat_columns = ['DevCenterID', 'SBUID', 'PositionID', 'PositionLevel', \n",
    "               'IsTrainee', 'LanguageLevelID', 'CustomerID', 'ProjectID', \n",
    "               'IsInternalProject', 'OnSite', 'CompetenceGroupID', 'FunctionalOfficeID',\n",
    "               'PaymentTypeId']\n",
    "\n",
    "X = df.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "from category_encoders.basen import BaseNEncoder\n",
    "encoder = BaseNEncoder(cols = cat_columns, base = 2)\n",
    "X = encoder.fit_transform(X)\n",
    "\n",
    "USE_SCALER = True\n",
    "RANDOM_SEED = 1\n",
    "set_seed()\n",
    "\n",
    "X[\"month\"] = X[\"Date\"].apply(get_month)\n",
    "X[\"year\"] = X[\"Date\"].apply(get_year)\n",
    "X = X.sort_values([\"year\",\"month\"])\n",
    "X[\"year_month\"] = X.apply(lambda row: str(row[\"year\"])+\"_\"+str(row[\"month\"]), axis=1)\n",
    "year_month = list(X.year_month.unique())\n",
    "mapping_year_month = dict(zip(year_month, range(len(year_month))))\n",
    "X[\"order_in_time\"] = X[\"year_month\"].map(mapping_year_month)\n",
    "splits = [[[0,9],[10,11]],\n",
    "          [[0,11],[12,13]],\n",
    "          [[0,13],[14,15]],\n",
    "          [[0,15],[16,17]],\n",
    "          [[0,17],[18,19]]]\n",
    "\n",
    "fold = 0\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "for split in splits:\n",
    "    fold += 1\n",
    "    if fold ==5:\n",
    "        continue;\n",
    "    \n",
    "    X_train = X.query(f\"order_in_time >= \"+str(split[0][0])+\" & order_in_time <\"+str(split[0][1]))\n",
    "    X_val = X.query(f\"order_in_time >= \"+str(split[1][0])+\" & order_in_time <\"+str(split[1][1]))\n",
    "    \n",
    "    X_val = X_val.sort_values(by=\"Date\").drop_duplicates(subset=[\"EmployeeID\"], keep=\"last\")\n",
    "    \n",
    "    \n",
    "    y_train = X_train['target']\n",
    "    y_val = list(X_val['target'])\n",
    "    \n",
    "    X_train =X_train.drop(columns=['EmployeeID',\"month\", \"year\", \"year_month\", \"order_in_time\", \"Date\",'target'])\n",
    "    X_val =X_val.drop(columns=['EmployeeID',\"month\", \"year\", \"year_month\", \"order_in_time\", \"Date\",'target'])\n",
    "    \n",
    "    if USE_SCALER:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "    \n",
    "    print(\"fold: \", fold)\n",
    "    print(\"train:\", len(X_train))\n",
    "    print(\"val:\",len(X_val))\n",
    "    print(\" \")\n",
    "    \n",
    "    print('FOLD #{}'.format(fold))\n",
    "    models = model_fit(X_train, y_train)\n",
    "    print('END OF MODEL FIT')\n",
    "    \n",
    "    y_pred = model_predict(X_val, models)\n",
    "\n",
    "    score = fbeta_score(y_val, y_pred, beta=1.7)\n",
    "    \n",
    "    print('Validation Score: {}'.format(score))\n",
    "    scores.append(score)\n",
    "    \n",
    "mean_score = np.mean(scores)\n",
    "print('MEAN OF SCOREs: {}'.format(mean_score))   \n",
    "\n",
    "\n",
    "y = X.target\n",
    "emps_X = X.EmployeeID\n",
    "X = X.drop(columns=['EmployeeID',\"month\", \"year\", \"year_month\", \"order_in_time\", \"Date\",'target'])\n",
    "\n",
    "model = model_fit(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction logic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "history.loc[:,'Date'] = list(pd.to_datetime(history['Date']))\n",
    "\n",
    "df = history.merge(employees)\n",
    "df['target'] = lbls\n",
    "\n",
    "X_test = df[df.target==2]\n",
    "\n",
    "X_test = X_test[X_test.EmployeeID.isin(set(submission.EmployeeID))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ids = X_test.EmployeeID\n",
    "X_test = X_test.drop(columns_to_drop, axis = 1)\n",
    "X_test = encoder.transform(X_test)\n",
    "X_test = X_test.drop(columns=['EmployeeID',\"Date\",'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'EmployeeID':emp_ids, 'target':preds[:,1]})\n",
    "result = pd.DataFrame({'EmployeeID':(result.groupby('EmployeeID').max().target>0.5).index, 'target':(result.groupby('EmployeeID').max().target>0.5).astype(int).values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('Mykola_initial_submit_max_score.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"../data/submission.csv\")\n",
    "len(submission.EmployeeID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00116D71-E87D-4B64-A566-1F29B2A798A8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0034ECA4-0562-4AC7-A826-4AE81C64D69F</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00384806-F711-41BA-A924-8F27E996F891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005B5FD6-FD19-4924-98E4-4C06F7F6BF2C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0061CAE7-B123-46B0-9BF7-E1E94E9AD80B</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>FFCFA379-9529-49EF-87BA-1522FE94B415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>FFE9E1F0-1DB1-4BA8-A8FB-026E7DBCF49F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>FFEBB9DA-B0CF-49AE-91D3-14A0BF22219E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>FFED12A3-5B28-4101-908A-2851CBADE045</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>FFF3B179-1D20-40FF-A330-A051BDF37301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                EmployeeID  target\n",
       "0     00116D71-E87D-4B64-A566-1F29B2A798A8       0\n",
       "1     0034ECA4-0562-4AC7-A826-4AE81C64D69F       0\n",
       "2     00384806-F711-41BA-A924-8F27E996F891       1\n",
       "3     005B5FD6-FD19-4924-98E4-4C06F7F6BF2C       1\n",
       "4     0061CAE7-B123-46B0-9BF7-E1E94E9AD80B       0\n",
       "...                                    ...     ...\n",
       "4151  FFCFA379-9529-49EF-87BA-1522FE94B415       0\n",
       "4152  FFE9E1F0-1DB1-4BA8-A8FB-026E7DBCF49F       1\n",
       "4153  FFEBB9DA-B0CF-49AE-91D3-14A0BF22219E       1\n",
       "4154  FFED12A3-5B28-4101-908A-2851CBADE045       0\n",
       "4155  FFF3B179-1D20-40FF-A330-A051BDF37301       1\n",
       "\n",
       "[4156 rows x 2 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Developing LSTM model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building train and test datasets:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "pd.options.display.max_colwidth=100\n",
    "pd.options.display.max_columns=300\n",
    "\n",
    "employees = pd.read_csv(\"../data/employees.csv\")\n",
    "history = pd.read_csv(\"../data/history.csv\")\n",
    "submission = pd.read_csv(\"../data/submission.csv\")\n",
    "\n",
    "history.loc[:,'Date'] = list(pd.to_datetime(history['Date']))\n",
    "\n",
    "def get_month(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[0])\n",
    "\n",
    "def get_year(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[-1])\n",
    "\n",
    "df = history.merge(employees)\n",
    "\n",
    "# for data labeling\n",
    "def label_df(data, n_month=3):\n",
    "    labels = []\n",
    "    for emp in data.EmployeeID.unique():\n",
    "        curr_emp = list(data[data.EmployeeID == emp]['DismissalDate'])\n",
    "        len_emp = len(curr_emp)\n",
    "        if pd.isnull(curr_emp[0]):\n",
    "            labels += [0 for _ in range(len_emp)]\n",
    "        else:\n",
    "            labels += [0 for _ in range(len_emp - 5)] + [10,10,50,100,1000]\n",
    "    return labels\n",
    "\n",
    "lbls = label_df(df)\n",
    "df['target'] = lbls\n",
    "df = df[df.target!=6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_drop = ['Date','HiringDate', 'DismissalDate']\n",
    "\n",
    "cat_columns = ['DevCenterID', 'SBUID', 'PositionID', 'PositionLevel', \n",
    "               'IsTrainee', 'LanguageLevelID', 'CustomerID', 'ProjectID', \n",
    "               'IsInternalProject', 'OnSite', 'CompetenceGroupID', 'FunctionalOfficeID',\n",
    "               'PaymentTypeId']\n",
    "\n",
    "X = df.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "from category_encoders.basen import BaseNEncoder\n",
    "encoder = BaseNEncoder(cols = cat_columns, base = 2)\n",
    "\n",
    "X = encoder.fit_transform(X)\n",
    "X = X.reset_index()\n",
    "\n",
    "tmp = X.EmployeeID\n",
    "target = X.target\n",
    "X.drop(['EmployeeID', 'target'], axis = 1, inplace = True)\n",
    "\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = cols)\n",
    "X['target'] = target\n",
    "X['EmployeeID'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_empls = list(set(X.EmployeeID)-set(submission.EmployeeID))[15:30]\n",
    "val_set = X[X.EmployeeID.isin(set(testing_empls))]\n",
    "val_set = val_set.groupby('EmployeeID').tail(5)\n",
    "train_set = X.drop(val_set.index)\n",
    "\n",
    "test_set = X[X.EmployeeID.isin(set(submission.EmployeeID))]\n",
    "test_set = test_set.groupby('EmployeeID').tail(5)\n",
    "train_set = train_set.drop(test_set.index)\n",
    "\n",
    "train_set.drop('index', axis = 1, inplace = True)\n",
    "test_set.drop('index', axis = 1, inplace = True)\n",
    "val_set.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test dataset:\n",
    "import tensorflow as tf\n",
    "\n",
    "cols = list(test_set.columns)\n",
    "cols.pop(-1)\n",
    "cols.pop(-1)\n",
    "\n",
    "X_test = [person[1][cols].values for person in test_set.groupby('EmployeeID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test dataset:\n",
    "import tensorflow as tf\n",
    "\n",
    "cols = list(test_set.columns)\n",
    "cols.pop(-1)\n",
    "cols.pop(-1)\n",
    "\n",
    "\n",
    "X_val = [person[1][cols].values for person in val_set.groupby('EmployeeID')]\n",
    "y_val = [person[1]['target'].values for person in val_set.groupby('EmployeeID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5373/5373 [00:00<00:00, 5976.60it/s] \n"
     ]
    }
   ],
   "source": [
    "### train dataset:\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "cols = list(train_set.columns)\n",
    "cols.pop(-1)\n",
    "\n",
    "data = [person[1][cols].values for person in train_set.groupby('EmployeeID')]\n",
    "\n",
    "# getting subsequences:\n",
    "def get_subsequence(sequence):\n",
    "    if sequence.shape[0]<6:\n",
    "        return []\n",
    "#     if (sequence.shape[0]>=2) and (sequence.shape[0]<6):\n",
    "#         return [sequence]\n",
    "    else:\n",
    "        tmp_data = []\n",
    "        for i in range(0, sequence.shape[0]-5):\n",
    "            tmp_data.append(sequence[i:i+6])\n",
    "        return tmp_data\n",
    "\n",
    "sub_data = []\n",
    "for x in tqdm(data):\n",
    "    sub_data = sub_data + get_subsequence(x)\n",
    "\n",
    "# x_train = [x[:-1,:-1].flatten() for x in sub_data]\n",
    "\n",
    "# # y_train = tf.keras.utils.to_categorical([x[-1, -1] for x in data])   # Expects class labels from 0 to n (-> subtract 1).\n",
    "# y_train = [x[-1, -1] for x in sub_data]\n",
    "# print(len(x_train))\n",
    "# print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "247608\n",
      "247608\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "for el in sub_data:\n",
    "    train_X += [i[:-1] for i in el]\n",
    "    train_y += [i[-1] for i in el]\n",
    "    \n",
    "print(len(train_X))\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20780"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = []\n",
    "for el in X_test:\n",
    "    test_X += [i for i in el]\n",
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X = []\n",
    "for el in X_val:\n",
    "    val_X += [i for i in el]\n",
    "val_y = []\n",
    "for el in y_val:\n",
    "    val_y += [i for i in el]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X, X_val, y, y_val = train_test_split(train_X, train_y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 198086 samples, validate on 49522 samples\n",
      "Epoch 1/40\n",
      "198086/198086 [==============================] - 8s 40us/sample - loss: 4117.5994 - mean_squared_error: 4117.3442 - val_loss: 3971.0601 - val_mean_squared_error: 3970.7964\n",
      "Epoch 2/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 4073.4485 - mean_squared_error: 4073.1599 - val_loss: 3967.3081 - val_mean_squared_error: 3966.9849\n",
      "Epoch 3/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 4046.9353 - mean_squared_error: 4046.5757 - val_loss: 3944.0762 - val_mean_squared_error: 3943.6826\n",
      "Epoch 4/40\n",
      "198086/198086 [==============================] - 8s 39us/sample - loss: 4004.4962 - mean_squared_error: 4004.0591 - val_loss: 3987.5011 - val_mean_squared_error: 3987.0195\n",
      "Epoch 5/40\n",
      "198086/198086 [==============================] - 8s 39us/sample - loss: 3955.3283 - mean_squared_error: 3954.7966 - val_loss: 4009.8696 - val_mean_squared_error: 4009.2817\n",
      "Epoch 6/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3907.0753 - mean_squared_error: 3906.4329 - val_loss: 4216.3966 - val_mean_squared_error: 4215.7065\n",
      "Epoch 7/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3819.2103 - mean_squared_error: 3818.4592 - val_loss: 4154.5310 - val_mean_squared_error: 4153.7168\n",
      "Epoch 8/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3718.5001 - mean_squared_error: 3717.6187 - val_loss: 4409.6477 - val_mean_squared_error: 4408.7002\n",
      "Epoch 9/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 3634.1584 - mean_squared_error: 3633.1382 - val_loss: 4122.7443 - val_mean_squared_error: 4121.6650\n",
      "Epoch 10/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 3540.0980 - mean_squared_error: 3538.9509 - val_loss: 4381.7561 - val_mean_squared_error: 4380.5474\n",
      "Epoch 11/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3442.8648 - mean_squared_error: 3441.5962 - val_loss: 4589.6158 - val_mean_squared_error: 4588.2969\n",
      "Epoch 12/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3347.2341 - mean_squared_error: 3345.8569 - val_loss: 4444.1348 - val_mean_squared_error: 4442.7051\n",
      "Epoch 13/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3269.3910 - mean_squared_error: 3267.9006 - val_loss: 5093.7662 - val_mean_squared_error: 5092.2354\n",
      "Epoch 14/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 3164.5809 - mean_squared_error: 3162.9985 - val_loss: 5029.1016 - val_mean_squared_error: 5027.4712\n",
      "Epoch 15/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3104.7811 - mean_squared_error: 3103.1021 - val_loss: 5496.3894 - val_mean_squared_error: 5494.6704\n",
      "Epoch 16/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 3039.7596 - mean_squared_error: 3037.9985 - val_loss: 5276.7838 - val_mean_squared_error: 5274.9829\n",
      "Epoch 17/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2966.3103 - mean_squared_error: 2964.4678 - val_loss: 4954.1267 - val_mean_squared_error: 4952.2461\n",
      "Epoch 18/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2897.3579 - mean_squared_error: 2895.4343 - val_loss: 5272.5892 - val_mean_squared_error: 5270.6299\n",
      "Epoch 19/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2832.3518 - mean_squared_error: 2830.3560 - val_loss: 5184.8997 - val_mean_squared_error: 5182.8662\n",
      "Epoch 20/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2788.7473 - mean_squared_error: 2786.6763 - val_loss: 5227.1289 - val_mean_squared_error: 5225.0244\n",
      "Epoch 21/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2739.6099 - mean_squared_error: 2737.4705 - val_loss: 6025.4616 - val_mean_squared_error: 6023.2915\n",
      "Epoch 22/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2662.4391 - mean_squared_error: 2660.2341 - val_loss: 6818.7267 - val_mean_squared_error: 6816.4854\n",
      "Epoch 23/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2638.4352 - mean_squared_error: 2636.1633 - val_loss: 6141.0138 - val_mean_squared_error: 6138.7070\n",
      "Epoch 24/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2607.2420 - mean_squared_error: 2604.9045 - val_loss: 4972.7155 - val_mean_squared_error: 4970.3535\n",
      "Epoch 25/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2571.4983 - mean_squared_error: 2569.1047 - val_loss: 5909.4934 - val_mean_squared_error: 5907.0752\n",
      "Epoch 26/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2488.8639 - mean_squared_error: 2486.4124 - val_loss: 5722.0963 - val_mean_squared_error: 5719.6147\n",
      "Epoch 27/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2471.5283 - mean_squared_error: 2469.0203 - val_loss: 6548.0951 - val_mean_squared_error: 6545.5610\n",
      "Epoch 28/40\n",
      "198086/198086 [==============================] - 8s 38us/sample - loss: 2419.7676 - mean_squared_error: 2417.2017 - val_loss: 8400.4992 - val_mean_squared_error: 8397.9053\n",
      "Epoch 29/40\n",
      "198086/198086 [==============================] - 8s 38us/sample - loss: 2380.8987 - mean_squared_error: 2378.2788 - val_loss: 8052.1240 - val_mean_squared_error: 8049.4800\n",
      "Epoch 30/40\n",
      "198086/198086 [==============================] - 8s 38us/sample - loss: 2341.9706 - mean_squared_error: 2339.3010 - val_loss: 7145.3499 - val_mean_squared_error: 7142.6484\n",
      "Epoch 31/40\n",
      "198086/198086 [==============================] - 8s 39us/sample - loss: 2334.8181 - mean_squared_error: 2332.0879 - val_loss: 6877.9845 - val_mean_squared_error: 6875.2295\n",
      "Epoch 32/40\n",
      "198086/198086 [==============================] - 8s 39us/sample - loss: 2351.9642 - mean_squared_error: 2349.1836 - val_loss: 5786.5974 - val_mean_squared_error: 5783.7944\n",
      "Epoch 33/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2298.0685 - mean_squared_error: 2295.2444 - val_loss: 8835.5575 - val_mean_squared_error: 8832.7129\n",
      "Epoch 34/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2239.0077 - mean_squared_error: 2236.1379 - val_loss: 6953.5339 - val_mean_squared_error: 6950.6396\n",
      "Epoch 35/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2230.3465 - mean_squared_error: 2227.4277 - val_loss: 9242.4036 - val_mean_squared_error: 9239.4688\n",
      "Epoch 36/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2206.4058 - mean_squared_error: 2203.4409 - val_loss: 6182.3952 - val_mean_squared_error: 6179.4058\n",
      "Epoch 37/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2150.0044 - mean_squared_error: 2146.9880 - val_loss: 7626.3734 - val_mean_squared_error: 7623.3369\n",
      "Epoch 38/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2151.4264 - mean_squared_error: 2148.3672 - val_loss: 8206.9091 - val_mean_squared_error: 8203.8242\n",
      "Epoch 39/40\n",
      "198086/198086 [==============================] - 7s 37us/sample - loss: 2145.4014 - mean_squared_error: 2142.2900 - val_loss: 6518.3202 - val_mean_squared_error: 6515.1836\n",
      "Epoch 40/40\n",
      "198086/198086 [==============================] - 7s 38us/sample - loss: 2095.8352 - mean_squared_error: 2092.6753 - val_loss: 10193.7955 - val_mean_squared_error: 10190.6104\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1afeb65748>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives)\n",
    "#     return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives)\n",
    "#     return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return (1+1.7**2)*((precision*recall)/(1.7**2*precision+recall))\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(1000, activation='relu', input_dim=90, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),))\n",
    "model.add(tf.keras.layers.Dense(500, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "# fit the keras model on the dataset\n",
    "model.fit(np.array(train_X), train_y, epochs=40, validation_split=0.2, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Testing prediction logic\n",
    "preds = model.predict(np.array(test_X)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = []\n",
    "for i in range(0,len(preds)-4,5):\n",
    "    tmp = preds[i:i+5]\n",
    "    if len(np.where(tmp>100)[0])>0 or (tmp[1:] == np.sort(tmp[1:])).all():\n",
    "        pp.append(1)\n",
    "    else:\n",
    "        pp.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1902"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# X_test = np.array(X_test)\n",
    "# preds = model.predict(X_test)\n",
    "epms = list(test_set.groupby('EmployeeID').count().index)\n",
    "\n",
    "result = pd.DataFrame({'EmployeeID':epms, 'target':pp})\n",
    "\n",
    "result.to_csv('Mykola_super_ugadaika.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD #1\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.39801147448588814\n",
      "FOLD #2\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.0\n",
      "FOLD #3\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.395730611776095\n",
      "FOLD #4\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.4140036409466461\n",
      "FOLD #5\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.39130705823347234\n",
      "MEAN OF SCOREs: 0.3198105570884203\n"
     ]
    }
   ],
   "source": [
    "# !pip install imblearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seed(random_state=RANDOM_SEED):\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "def model_fit(X_train, y_train):\n",
    "    clf2 = RUSBoostClassifier(n_estimators=200)\n",
    "    clf2 = clf2.fit(X_train, y_train)\n",
    "    return clf2\n",
    "\n",
    "def model_predict(X, models):\n",
    "    preds = models.predict(X)\n",
    "    return preds\n",
    "\n",
    "# def model_fit(X_train, y_train):\n",
    "#     model = tf.keras.models.Sequential()\n",
    "#     model.add(tf.keras.layers.Dense(2000, activation='relu', input_dim=455,))\n",
    "#     model.add(tf.keras.layers.Dense(1000, activation='relu',))\n",
    "#     model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "#     optimizer = tf.keras.optimizers.Adam(lr=0.00005)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc',f1_m,precision_m, recall_m])\n",
    "#     # fit the keras model on the dataset\n",
    "#     model.fit(np.array(X_train), y_train, epochs=15, validation_split=0.0001, batch_size=512, verbose = 0)\n",
    "#     return model\n",
    "\n",
    "# def model_predict(X, models):\n",
    "#     preds = models.predict(X).flatten()>0.5\n",
    "#     return preds\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "fold = 0\n",
    "scores = []\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_val = X[train_index], X[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "    print('FOLD #{}'.format(fold))\n",
    "    models = model_fit(X_train, y_train)\n",
    "    print('END OF MODEL FIT')\n",
    "    \n",
    "    y_pred = model_predict(X_val, models)\n",
    "\n",
    "    score = fbeta_score(y_val, y_pred, beta=1.7)\n",
    "    \n",
    "    print('Validation Score: {}'.format(score))\n",
    "    scores.append(score)\n",
    "    \n",
    "mean_score = np.mean(scores)\n",
    "print('MEAN OF SCOREs: {}'.format(mean_score))  \n",
    "\n",
    "model = model_fit(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "preds = model.predict(X_test)\n",
    "epms = list(test_set.groupby('EmployeeID').count().index)\n",
    "\n",
    "result = pd.DataFrame({'EmployeeID':epms, 'target':preds})\n",
    "\n",
    "result.to_csv('Mykola_initial_NN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3488"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00116D71-E87D-4B64-A566-1F29B2A798A8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0034ECA4-0562-4AC7-A826-4AE81C64D69F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00384806-F711-41BA-A924-8F27E996F891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005B5FD6-FD19-4924-98E4-4C06F7F6BF2C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0061CAE7-B123-46B0-9BF7-E1E94E9AD80B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>FFCFA379-9529-49EF-87BA-1522FE94B415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>FFE9E1F0-1DB1-4BA8-A8FB-026E7DBCF49F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>FFEBB9DA-B0CF-49AE-91D3-14A0BF22219E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>FFED12A3-5B28-4101-908A-2851CBADE045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>FFF3B179-1D20-40FF-A330-A051BDF37301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                EmployeeID  target\n",
       "0     00116D71-E87D-4B64-A566-1F29B2A798A8       1\n",
       "1     0034ECA4-0562-4AC7-A826-4AE81C64D69F       1\n",
       "2     00384806-F711-41BA-A924-8F27E996F891       1\n",
       "3     005B5FD6-FD19-4924-98E4-4C06F7F6BF2C       1\n",
       "4     0061CAE7-B123-46B0-9BF7-E1E94E9AD80B       1\n",
       "...                                    ...     ...\n",
       "4151  FFCFA379-9529-49EF-87BA-1522FE94B415       1\n",
       "4152  FFE9E1F0-1DB1-4BA8-A8FB-026E7DBCF49F       1\n",
       "4153  FFEBB9DA-B0CF-49AE-91D3-14A0BF22219E       1\n",
       "4154  FFED12A3-5B28-4101-908A-2851CBADE045       1\n",
       "4155  FFF3B179-1D20-40FF-A330-A051BDF37301       1\n",
       "\n",
       "[4156 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
