{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building train and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building train and test datasets:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "pd.options.display.max_colwidth=100\n",
    "pd.options.display.max_columns=300\n",
    "\n",
    "employees = pd.read_csv(\"../data/employees.csv\")\n",
    "history = pd.read_csv(\"../data/history.csv\")\n",
    "submission = pd.read_csv(\"../data/submission.csv\")\n",
    "\n",
    "history.loc[:,'Date'] = list(pd.to_datetime(history['Date']))\n",
    "\n",
    "def get_month(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[0])\n",
    "\n",
    "def get_year(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[-1])\n",
    "\n",
    "df = history.merge(employees)\n",
    "\n",
    "# for data labeling\n",
    "def label_df(data, n_month=3):\n",
    "    labels = []\n",
    "    for emp in data.EmployeeID.unique():\n",
    "        curr_emp = list(data[data.EmployeeID == emp]['DismissalDate'])\n",
    "        len_emp = len(curr_emp)\n",
    "        if pd.isnull(curr_emp[0]):\n",
    "            labels += [0 for _ in range(len_emp)]\n",
    "        else:\n",
    "            labels += [0 for _ in range(len_emp - 3)] + [1,1,1]\n",
    "    return labels\n",
    "\n",
    "lbls = label_df(df)\n",
    "df['target'] = lbls\n",
    "df = df[df.target!=6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "columns_to_drop = ['Date','HiringDate', 'DismissalDate']\n",
    "\n",
    "cat_columns = ['DevCenterID', 'SBUID', 'PositionID', 'PositionLevel', \n",
    "               'IsTrainee', 'LanguageLevelID', 'CustomerID', 'ProjectID', \n",
    "               'IsInternalProject', 'OnSite', 'CompetenceGroupID', 'FunctionalOfficeID',\n",
    "               'PaymentTypeId']\n",
    "\n",
    "X = df.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "from category_encoders.basen import BaseNEncoder\n",
    "encoder = BaseNEncoder(cols = cat_columns, base = 3)\n",
    "\n",
    "X = encoder.fit_transform(X)\n",
    "X = X.reset_index()\n",
    "\n",
    "tmp = X.EmployeeID\n",
    "target = X.target\n",
    "X.drop(['EmployeeID', 'target'], axis = 1, inplace = True)\n",
    "\n",
    "cols = X.columns\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns = cols)\n",
    "X['target'] = target\n",
    "X['EmployeeID'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_empls = list(set(X.EmployeeID)-set(submission.EmployeeID))[15:30]\n",
    "\n",
    "val_set = X[X.EmployeeID.isin(set(testing_empls))]\n",
    "val_set = val_set.groupby('EmployeeID').tail(6)\n",
    "train_set = X.drop(val_set.index)\n",
    "\n",
    "test_set = X[X.EmployeeID.isin(set(submission.EmployeeID))]\n",
    "test_set = test_set.groupby('EmployeeID').tail(3)\n",
    "train_set = train_set.drop(test_set.index)\n",
    "\n",
    "train_set.drop('index', axis = 1, inplace = True)\n",
    "test_set.drop('index', axis = 1, inplace = True)\n",
    "val_set.drop('index', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/trokhymovych/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "### test dataset:\n",
    "import tensorflow as tf\n",
    "\n",
    "cols = list(test_set.columns)\n",
    "cols.pop(-1)\n",
    "cols.pop(-1)\n",
    "\n",
    "X_test = [person[1][cols].values for person in test_set.groupby('EmployeeID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test dataset:\n",
    "import tensorflow as tf\n",
    "\n",
    "cols = list(test_set.columns)\n",
    "cols.pop(-1)\n",
    "cols.pop(-1)\n",
    "\n",
    "\n",
    "X_val = [person[1][cols].values for person in val_set.groupby('EmployeeID')]\n",
    "y_val = [person[1]['target'].values for person in val_set.groupby('EmployeeID')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5373/5373 [00:00<00:00, 8040.57it/s] \n"
     ]
    }
   ],
   "source": [
    "### train dataset:\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "cols = list(train_set.columns)\n",
    "cols.pop(-1)\n",
    "\n",
    "data = [person[1][cols].values for person in train_set.groupby('EmployeeID')]\n",
    "\n",
    "# getting subsequences:\n",
    "def get_subsequence(sequence):\n",
    "    if sequence.shape[0]<6:\n",
    "        return []\n",
    "#     if (sequence.shape[0]>=2) and (sequence.shape[0]<6):\n",
    "#         return [sequence]\n",
    "    else:\n",
    "        tmp_data = []\n",
    "        for i in range(0, sequence.shape[0]-5):\n",
    "            tmp_data.append(sequence[i:i+6])\n",
    "        return tmp_data\n",
    "\n",
    "sub_data = []\n",
    "for x in tqdm(data):\n",
    "    sub_data = sub_data + get_subsequence(x)\n",
    "\n",
    "# x_train = [x[:-1,:-1].flatten() for x in sub_data]\n",
    "\n",
    "# # y_train = tf.keras.utils.to_categorical([x[-1, -1] for x in data])   # Expects class labels from 0 to n (-> subtract 1).\n",
    "# y_train = [x[-1, -1] for x in sub_data]\n",
    "# print(len(x_train))\n",
    "# print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292674\n",
      "292674\n"
     ]
    }
   ],
   "source": [
    "train_X = []\n",
    "train_y = []\n",
    "for el in sub_data:\n",
    "    train_X += [i[:-1] for i in el]\n",
    "    train_y += [i[-1] for i in el]\n",
    "    \n",
    "print(len(train_X))\n",
    "print(len(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = []\n",
    "for el in X_test:\n",
    "    test_X += [i for i in el]\n",
    "len(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = []\n",
    "for el in X_val:\n",
    "    val_X += [i for i in el]\n",
    "val_y = []\n",
    "for el in y_val:\n",
    "    val_y += [i for i in el]\n",
    "val_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X, X_val, y, y_val = train_test_split(train_X, train_y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 278040 samples, validate on 14634 samples\n",
      "Epoch 1/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.1468 - val_loss: 0.0915\n",
      "Epoch 2/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0940 - val_loss: 0.0889\n",
      "Epoch 3/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0918 - val_loss: 0.0950\n",
      "Epoch 4/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0894 - val_loss: 0.0898\n",
      "Epoch 5/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0880 - val_loss: 0.0951\n",
      "Epoch 6/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0856 - val_loss: 0.0991\n",
      "Epoch 7/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0853 - val_loss: 0.1047\n",
      "Epoch 8/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0832 - val_loss: 0.1053\n",
      "Epoch 9/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0824 - val_loss: 0.1049\n",
      "Epoch 10/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0816 - val_loss: 0.1028\n",
      "Epoch 11/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0791 - val_loss: 0.1029\n",
      "Epoch 12/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0796 - val_loss: 0.1119\n",
      "Epoch 13/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0788 - val_loss: 0.0994\n",
      "Epoch 14/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0770 - val_loss: 0.1121\n",
      "Epoch 15/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0773 - val_loss: 0.1120\n",
      "Epoch 16/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0758 - val_loss: 0.1087\n",
      "Epoch 17/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0741 - val_loss: 0.1223\n",
      "Epoch 18/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0750 - val_loss: 0.1087\n",
      "Epoch 19/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0731 - val_loss: 0.1288\n",
      "Epoch 20/20\n",
      "278040/278040 [==============================] - 2s - loss: 0.0731 - val_loss: 0.1228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a49b8bb00>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Lambda, Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import mnist\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "\n",
    "# def recall_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "#     recall = true_positives / (possible_positives)\n",
    "#     return recall\n",
    "\n",
    "# def precision_m(y_true, y_pred):\n",
    "#     true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "#     predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "#     precision = true_positives / (predicted_positives)\n",
    "#     return precision\n",
    "\n",
    "# def f1_m(y_true, y_pred):\n",
    "#     precision = precision_m(y_true, y_pred)\n",
    "#     recall = recall_m(y_true, y_pred)\n",
    "#     return (1+1.7**2)*((precision*recall)/(1.7**2*precision+recall))\n",
    "\n",
    "\n",
    "# model = tf.keras.models.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(1000, activation='relu', input_dim=90, kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),))\n",
    "# model.add(tf.keras.layers.Dense(500, activation='relu', kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),))\n",
    "# model.add(tf.keras.layers.Dense(1))\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# model.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
    "# # fit the keras model on the dataset\n",
    "# model.fit(np.array(train_X), train_y, epochs=40, validation_split=0.2, batch_size=512)\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "original_dim = 66\n",
    "intermediate_dim = 100\n",
    "latent_dim = 1\n",
    "epsilon_std = 0.1\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "x = Input(shape = (original_dim,))\n",
    "h = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(latent_dim,),\n",
    "                              mean=0., stddev=epsilon_std)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
    "\n",
    "decoder_h = Dense(intermediate_dim, activation='relu')\n",
    "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)\n",
    "\n",
    "\n",
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)\n",
    "\n",
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss\n",
    "\n",
    "vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "vae.fit(np.array(train_X), np.array(train_y),\n",
    "        validation_split=0.05,\n",
    "        shuffle=True,\n",
    "        epochs=20,\n",
    "        batch_size=batch_size,\n",
    "        verbose = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = encoder.predict(np.array(val_X))\n",
    "val_y = np.array(val_y)\n",
    "\n",
    "pred_new = []\n",
    "val_new = []\n",
    "for i in range(0, len(val_X) -2,3):\n",
    "    pred_new.append(pred[i:i+3].mean(axis = 0))\n",
    "    val_new.append(val_y[i:i+3].mean(axis = 0))\n",
    "pred_new = np.array(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a69cc0198>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(pred_new[:,0], y = np.zeros(len(pred_new)), c = val_new)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_new.flatten()<0.05).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = encoder.predict(np.array(test_X))\n",
    "pred_new = []\n",
    "val_new = []\n",
    "\n",
    "for i in range(0, len(test_X) -2,3):\n",
    "    pred_new.append(pred[i:i+3].min(axis = 0))\n",
    "#     val_new.append(val_y[i:i+3].mean(axis = 0))\n",
    "pred_new = np.array(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_new = (pred_new.flatten()<0.).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "\n",
    "\n",
    "###### Testing prediction logic\n",
    "preds = model.predict(np.array(test_X)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = []\n",
    "for i in range(0,len(preds)-4,5):\n",
    "    tmp = preds[i:i+5]\n",
    "    if len(np.where(tmp>100)[0])>0 or (tmp[1:] == np.sort(tmp[1:])).all():\n",
    "        pp.append(1)\n",
    "    else:\n",
    "        pp.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1902"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# X_test = np.array(X_test)\n",
    "# preds = model.predict(X_test)\n",
    "epms = list(test_set.groupby('EmployeeID').count().index)\n",
    "\n",
    "result = pd.DataFrame({'EmployeeID':epms, 'target':pred_new})\n",
    "\n",
    "result.to_csv('Mykola_super_ugadaika_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(train_X)\n",
    "y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292674, 66)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.ensemble import RUSBoostClassifier\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import random\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seed(random_state=RANDOM_SEED):\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "# def model_fit(X_train, y_train):\n",
    "#     clf2 = RUSBoostClassifier(n_estimators=200)\n",
    "#     clf2 = clf2.fit(X_train, y_train)\n",
    "#     return clf2\n",
    "\n",
    "# def model_predict(X, models):\n",
    "#     preds = models.predict(X)\n",
    "#     return preds\n",
    "\n",
    "def model_fit(X_train, y_train):\n",
    "    clf2 = SVC(class_weight = 'balanced')\n",
    "    clf2 = clf2.fit(X_train, y_train)\n",
    "    return clf2\n",
    "\n",
    "def model_predict(X, models):\n",
    "    preds = models.predict(X)\n",
    "    return preds\n",
    "\n",
    "# def model_fit(X_train, y_train):\n",
    "#     model = tf.keras.models.Sequential()\n",
    "#     model.add(tf.keras.layers.Dense(2000, activation='relu', input_dim=455,))\n",
    "#     model.add(tf.keras.layers.Dense(1000, activation='relu',))\n",
    "#     model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "#     optimizer = tf.keras.optimizers.Adam(lr=0.00005)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc',f1_m,precision_m, recall_m])\n",
    "#     # fit the keras model on the dataset\n",
    "#     model.fit(np.array(X_train), y_train, epochs=15, validation_split=0.0001, batch_size=512, verbose = 0)\n",
    "#     return model\n",
    "\n",
    "# def model_predict(X, models):\n",
    "#     preds = models.predict(X).flatten()>0.5\n",
    "#     return preds\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# fold = 0\n",
    "# scores = []\n",
    "# for train_index, test_index in kf.split(X):\n",
    "#     fold += 1\n",
    "#     print('FOLD #{}'.format(fold))\n",
    "#     X_train, X_val = X[train_index], X[test_index]\n",
    "#     y_train, y_val = y[train_index], y[test_index]\n",
    "    \n",
    "#     print('FOLD #{}'.format(fold))\n",
    "#     models = model_fit(X_train, y_train)\n",
    "#     print('END OF MODEL FIT')\n",
    "    \n",
    "#     y_pred = model_predict(X_val, models)\n",
    "\n",
    "#     score = fbeta_score(y_val, y_pred, beta=1.7)\n",
    "    \n",
    "#     print('Validation Score: {}'.format(score))\n",
    "#     scores.append(score)\n",
    "    \n",
    "# mean_score = np.mean(scores)\n",
    "# print('MEAN OF SCOREs: {}'.format(mean_score))  \n",
    "\n",
    "model = model_fit(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "preds = model.predict(X_test)\n",
    "epms = list(test_set.groupby('EmployeeID').count().index)\n",
    "\n",
    "result = pd.DataFrame({'EmployeeID':epms, 'target':preds})\n",
    "\n",
    "result.to_csv('Mykola_initial_NN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3488"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EmployeeID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00116D71-E87D-4B64-A566-1F29B2A798A8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0034ECA4-0562-4AC7-A826-4AE81C64D69F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00384806-F711-41BA-A924-8F27E996F891</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005B5FD6-FD19-4924-98E4-4C06F7F6BF2C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0061CAE7-B123-46B0-9BF7-E1E94E9AD80B</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4151</th>\n",
       "      <td>FFCFA379-9529-49EF-87BA-1522FE94B415</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>FFE9E1F0-1DB1-4BA8-A8FB-026E7DBCF49F</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4153</th>\n",
       "      <td>FFEBB9DA-B0CF-49AE-91D3-14A0BF22219E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4154</th>\n",
       "      <td>FFED12A3-5B28-4101-908A-2851CBADE045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>FFF3B179-1D20-40FF-A330-A051BDF37301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                EmployeeID  target\n",
       "0     00116D71-E87D-4B64-A566-1F29B2A798A8       1\n",
       "1     0034ECA4-0562-4AC7-A826-4AE81C64D69F       1\n",
       "2     00384806-F711-41BA-A924-8F27E996F891       1\n",
       "3     005B5FD6-FD19-4924-98E4-4C06F7F6BF2C       1\n",
       "4     0061CAE7-B123-46B0-9BF7-E1E94E9AD80B       1\n",
       "...                                    ...     ...\n",
       "4151  FFCFA379-9529-49EF-87BA-1522FE94B415       1\n",
       "4152  FFE9E1F0-1DB1-4BA8-A8FB-026E7DBCF49F       1\n",
       "4153  FFEBB9DA-B0CF-49AE-91D3-14A0BF22219E       1\n",
       "4154  FFED12A3-5B28-4101-908A-2851CBADE045       1\n",
       "4155  FFF3B179-1D20-40FF-A330-A051BDF37301       1\n",
       "\n",
       "[4156 rows x 2 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
