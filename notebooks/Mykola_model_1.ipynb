{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "pd.options.display.max_colwidth=100\n",
    "pd.options.display.max_columns=300\n",
    "\n",
    "employees = pd.read_csv(\"../data/employees.csv\")\n",
    "history = pd.read_csv(\"../data/history.csv\")\n",
    "submission = pd.read_csv(\"../data/submission.csv\")\n",
    "\n",
    "# history.loc[:,'Date'] = list(pd.to_datetime(history['Date']))\n",
    "\n",
    "def get_month(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[0])\n",
    "\n",
    "def get_year(text):\n",
    "    if type(text) == str:\n",
    "        numbers = text.split(\"/\")\n",
    "        return int(numbers[-1])\n",
    "\n",
    "df = history.merge(employees)\n",
    "\n",
    "# for data labeling\n",
    "def label_df(data, n_month=3):\n",
    "    labels = []\n",
    "    for emp in data.EmployeeID.unique():\n",
    "        curr_emp = list(data[data.EmployeeID == emp]['DismissalDate'])\n",
    "        len_emp = len(curr_emp)\n",
    "        if pd.isnull(curr_emp[0]):\n",
    "            labels += [0 for _ in range(len_emp - n_month)] + [2 for _ in range(n_month)]\n",
    "        else:\n",
    "            labels += [0 for _ in range(len_emp - n_month)] + [1 for _ in range(n_month)]\n",
    "    return labels\n",
    "\n",
    "lbls = label_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = lbls\n",
    "df = df[df.target!=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['EmployeeID', 'HiringDate', 'DismissalDate']\n",
    "\n",
    "cat_columns = ['DevCenterID', 'SBUID', 'PositionID', 'PositionLevel', \n",
    "               'IsTrainee', 'LanguageLevelID', 'CustomerID', 'ProjectID', \n",
    "               'IsInternalProject', 'OnSite', 'CompetenceGroupID', 'FunctionalOfficeID',\n",
    "               'PaymentTypeId']\n",
    "\n",
    "X = df.drop(columns_to_drop, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.basen import BaseNEncoder\n",
    "encoder = BaseNEncoder(cols = cat_columns, base = 2)\n",
    "X = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import random\n",
    "\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import backend as K\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Visualize training history\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import keras\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    \n",
    "    beta = 1.7\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    \n",
    "    return (1+beta**2)\n",
    "\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#           optimizer= \"adam\",\n",
    "#           metrics=[f1])\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seed(random_state=RANDOM_SEED):\n",
    "    random.seed(random_state)\n",
    "    np.random.seed(random_state)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "def model_fit(X_train, y_train):\n",
    "    clf2 = BalancedRandomForestClassifier(n_estimators=200, n_jobs = 8)\n",
    "    clf2 = clf2.fit(X_train, y_train)\n",
    "    return clf2\n",
    "\n",
    "def model_predict(X, models):\n",
    "    preds = models.predict(X)\n",
    "    return preds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def model_fit(X_train, y_train):\n",
    "#     # create model\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(1500, input_dim=X_train.shape[1], activation='relu', activity_regularizer=l2(0.00001)))\n",
    "#     model.add(Dense(500, activation='relu', activity_regularizer=l2(0.00001)))\n",
    "#     model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    \n",
    "#     # Compile model\n",
    "#     optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "#     history = model.fit(X_train, y_train, validation_split=0.1, epochs=5, batch_size=512, verbose=1)\n",
    "#     return model\n",
    "\n",
    "# def model_predict(X, models):\n",
    "#     preds = models.predict(X)\n",
    "#     return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  1\n",
      "train: 50879\n",
      "val: 12697\n",
      " \n",
      "FOLD #1\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.42974819211834264\n",
      "fold:  2\n",
      "train: 50859\n",
      "val: 12717\n",
      " \n",
      "FOLD #2\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.4164808435567681\n",
      "fold:  3\n",
      "train: 50893\n",
      "val: 12683\n",
      " \n",
      "FOLD #3\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.4302827517187582\n",
      "fold:  4\n",
      "train: 50809\n",
      "val: 12767\n",
      " \n",
      "FOLD #4\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.42244825115876394\n",
      "fold:  5\n",
      "train: 50864\n",
      "val: 12712\n",
      " \n",
      "FOLD #5\n",
      "END OF MODEL FIT\n",
      "Validation Score: 0.4194693352197921\n",
      "MEAN OF SCOREs: 0.423685874754485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "USE_SCALER = True\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "X[\"month\"] = X[\"Date\"].apply(get_month)\n",
    "X[\"year\"] = X[\"Date\"].apply(get_year)\n",
    "X = X.sort_values([\"year\",\"month\"])\n",
    "X[\"year_month\"] = X.apply(lambda row: str(row[\"year\"])+\"_\"+str(row[\"month\"]), axis=1)\n",
    "year_month = list(X.year_month.unique())\n",
    "mapping_year_month = dict(zip(year_month, range(len(year_month))))\n",
    "X[\"order_in_time\"] = X[\"year_month\"].map(mapping_year_month)\n",
    "splits = [[[0,9],[10,11]],\n",
    "          [[0,11],[12,13]],\n",
    "          [[0,13],[14,15]],\n",
    "          [[0,15],[16,17]],\n",
    "          [[0,17],[18,19]]]\n",
    "\n",
    "fold = 0\n",
    "scores = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=RANDOM_SEED, shuffle=True)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "# for split in splits:\n",
    "#     fold += 1\n",
    "    \n",
    "#     X_train = X.query(f\"order_in_time >= \"+str(split[0][0])+\" & order_in_time <\"+str(split[0][1]))\n",
    "#     X_val = X.query(f\"order_in_time >= \"+str(split[1][0])+\" & order_in_time <\"+str(split[1][1]))\n",
    "    \n",
    "#     y_train = X_train['target']\n",
    "#     y_val = list(X_val['target'])\n",
    "    \n",
    "#     X_train =X_train.drop(columns=[\"month\", \"year\", \"year_month\", \"order_in_time\", \"Date\",'target'])\n",
    "#     X_val =X_val.drop(columns=[\"month\", \"year\", \"year_month\", \"order_in_time\", \"Date\",'target'])\n",
    "\n",
    "tmp = 0\n",
    "tmp2 = 0\n",
    "\n",
    "y = X.target\n",
    "X = X.drop(columns=[\"month\", \"year\", \"year_month\", \"order_in_time\", \"Date\",'target'])\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    fold += 1\n",
    "    X_train, X_val = X.loc[X.index.intersection(train_index)], X.loc[X.index.intersection(test_index)]\n",
    "    y_train, y_val = y.loc[y.index.intersection(train_index)], y.loc[y.index.intersection(test_index)]\n",
    "    \n",
    "    if USE_SCALER:\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "    \n",
    "    print(\"fold: \", fold)\n",
    "    print(\"train:\", len(X_train))\n",
    "    print(\"val:\",len(X_val))\n",
    "    print(\" \")\n",
    "    \n",
    "    print('FOLD #{}'.format(fold))\n",
    "    models = model_fit(X_train, y_train)\n",
    "    print('END OF MODEL FIT')\n",
    "    \n",
    "    y_pred = model_predict(X_val, models)\n",
    "    \n",
    "    tmp = y_pred\n",
    "    tmp2 = y_val\n",
    "\n",
    "    score = fbeta_score(y_val, y_pred, beta=1.7)\n",
    "    \n",
    "    print('Validation Score: {}'.format(score))\n",
    "    scores.append(score)\n",
    "    \n",
    "mean_score = np.mean(scores)\n",
    "print('MEAN OF SCOREs: {}'.format(mean_score))   \n",
    "\n",
    "model = model_fit(X, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "history.loc[:,'Date'] = list(pd.to_datetime(history['Date']))\n",
    "\n",
    "df = history.merge(employees)\n",
    "df['target'] = lbls\n",
    "\n",
    "X_test = df[df.target==2]\n",
    "X_test = X_test[X_test.Date == datetime(2019,2,1)]\n",
    "\n",
    "X_test = X_test[X_test.EmployeeID.isin(set(submission.EmployeeID))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_ids = X_test.EmployeeID\n",
    "X_test = X_test.drop(columns_to_drop, axis = 1)\n",
    "\n",
    "X_test = encoder.transform(X_test)\n",
    "\n",
    "X_test = X_test.drop(columns=[\"Date\",'target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'EmployeeID':emp_ids, 'target':preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('Mykola_initial_submit.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(\"../data/submission.csv\")\n",
    "len(submission.EmployeeID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
